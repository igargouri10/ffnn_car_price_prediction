# -*- coding: utf-8 -*-
"""hw4-IsmailGargouri.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1glwLTSNW1_fHjvOqtLNjEkB7RM-s0MIl
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re

# Load and Preprocess Dataset

# Load dataset
df = pd.read_csv('Car Price(in).csv', low_memory=False)

# Currency conversion: INR to USD
rupee_to_usd = 83

def convert_price_to_usd(price_str):
    if pd.isnull(price_str):
        return None
    price_str = price_str.replace('Lakh', '').replace(',', '').strip()
    try:
        price_in_lakh = float(price_str)
    except:
        return None
    return round((price_in_lakh * 100000) / rupee_to_usd, 2)

# Apply conversion
df['Car Prices (In rupee)'] = df['Car Prices (In rupee)'].apply(convert_price_to_usd)

# Rename column for clarity
df.rename(columns={'Car Prices (In rupee)': 'Car Prices (USD)'}, inplace=True)

# Distance conversion: kilometers to miles
def convert_kms_to_miles(kms_str):
    if pd.isnull(kms_str):
        return None
    kms_str = kms_str.replace('kms', '').replace(',', '').strip()
    try:
        kms = float(kms_str)
    except:
        return None
    return round(kms * 0.621371, 2)

# Apply distance conversion
df['Distance driven (in miles)'] = df['kms Driven'].apply(convert_kms_to_miles)
df.drop(columns=['kms Driven'], inplace=True)

# Clean 'Ownership' field to extract number of owners
def clean_ownership(ownership_str):
    if pd.isnull(ownership_str):
        return None
    match = re.search(r'\d+', ownership_str)
    return int(match.group()) if match else None

df['Ownership'] = df['Ownership'].apply(clean_ownership)

# Clean 'Seats' field
def clean_seats(seats_str):
    if pd.isnull(seats_str):
        return None
    match = re.search(r'\d+', seats_str)
    return int(match.group()) if match else None

df['Seats'] = df['Seats'].apply(clean_seats)

# Encode 'Transmission' column
def encode_transmission(transmission_str):
    if pd.isnull(transmission_str):
        return None
    return 0 if transmission_str.strip().lower() == 'automatic' else 1

df['Transmission'] = df['Transmission'].apply(encode_transmission)

# Clean 'Engine' column
def clean_engine(engine_str):
    if pd.isnull(engine_str):
        return None
    match = re.search(r'\d+', engine_str)
    return int(match.group()) if match else None

df['Engine (cc)'] = df['Engine'].apply(clean_engine)
df.drop(columns=['Engine'], inplace=True)

# Split 'Car Name' into Brand and Model
def split_car_name(name):
    if pd.isnull(name):
        return None, None
    parts = name.split(' ', 1)
    return parts[0], parts[1] if len(parts) > 1 else (parts[0], None)

df[['Car Brand Name', 'Car Model']] = df['Car Name'].apply(lambda x: pd.Series(split_car_name(x)))
df.drop(columns=['Car Name'], inplace=True)

# Map Car Brand to Region
brand_to_region = {
    'BMW': 'Europe', 'Audi': 'Europe', 'Mercedes-Benz': 'Europe', 'Volkswagen': 'Europe',
    'Skoda': 'Europe', 'Renault': 'Europe', 'Volvo': 'Europe', 'Porsche': 'Europe',
    'Mini': 'Europe', 'Land': 'Europe', 'Jaguar': 'Europe', 'Peugeot': 'Europe', 'Fiat': 'Europe',
    'Maruti': 'Asia', 'Hyundai': 'Asia', 'Honda': 'Asia', 'Toyota': 'Asia', 'Kia': 'Asia',
    'Nissan': 'Asia', 'Datsun': 'Asia', 'Suzuki': 'Asia', 'Mitsubishi': 'Asia',
    'Mahindra': 'Asia', 'Tata': 'Asia', 'Isuzu': 'Asia', 'Lexus': 'Asia',
    'Ford': 'US', 'Jeep': 'US', 'Chevrolet': 'US'
}

def map_brand_to_region(brand):
    if pd.isnull(brand):
        return 'Other'
    return brand_to_region.get(brand, 'Other')

df['Car Brand Region'] = df['Car Brand Name'].apply(map_brand_to_region)

# Encode 'Fuel Type'
fuel_type_mapping = {'Petrol': 0, 'Diesel': 1, 'Cng': 2, 'Lpg': 3, 'Electric': 4}
df['Fuel Type'] = df['Fuel Type'].apply(lambda x: fuel_type_mapping.get(x, None))

# Encode 'Car Brand Region'
region_mapping = {'Europe': 0, 'Asia': 1, 'US': 2, 'Other': 3}
df['Car Brand Region'] = df['Car Brand Region'].apply(lambda x: region_mapping.get(x, None))

# Handle missing values in Car Prices
df['Car Prices (USD)'].fillna(df['Car Prices (USD)'].mean(), inplace=True)

# Define a helper function to automate plot saving
# Save figure with auto-folder and close
def save_plot(fig, filename, folder='plots'):
    import os
    if not os.path.exists(folder):
        os.makedirs(folder)
    fig.savefig(f"{folder}/{filename}")
    plt.close(fig)

# Save All Figures into plots/ Folder

def save_plot(fig, filename, folder='plots'):
    import os
    if not os.path.exists(folder):
        os.makedirs(folder)
    fig.savefig(f"{folder}/{filename}")
    plt.close(fig)

# 1. Histogram of Car Prices
fig, ax = plt.subplots()
df['Car Prices (USD)'].hist(ax=ax, bins=30)
ax.set_title('Distribution of Car Prices')
ax.set_xlabel('Price (USD)')
ax.set_ylabel('Count')
save_plot(fig, 'histogram_car_prices.png')

# 2. Boxplot of Car Prices
fig, ax = plt.subplots()
sns.boxplot(x=df['Car Prices (USD)'], ax=ax)
ax.set_title('Boxplot of Car Prices')
save_plot(fig, 'boxplot_car_prices.png')

# 3. Boxplot of Distance Driven
fig, ax = plt.subplots()
sns.boxplot(x=df['Distance driven (in miles)'], ax=ax)
ax.set_title('Boxplot of Distance Driven')
save_plot(fig, 'boxplot_distance_driven.png')

# 4. Boxplot of Engine Size
fig, ax = plt.subplots()
sns.boxplot(x=df['Engine (cc)'], ax=ax)
ax.set_title('Boxplot of Engine Size')
save_plot(fig, 'boxplot_engine_size.png')

# 5. Scatterplot Distance vs Price
fig, ax = plt.subplots()
sns.scatterplot(x='Distance driven (in miles)', y='Car Prices (USD)', data=df, ax=ax)
ax.set_title('Scatterplot: Distance Driven vs Car Price')
save_plot(fig, 'scatterplot_distance_vs_price.png')

# 6. Scatterplot Engine vs Price
fig, ax = plt.subplots()
sns.scatterplot(x='Engine (cc)', y='Car Prices (USD)', data=df, ax=ax)
ax.set_title('Scatterplot: Engine Size vs Car Price')
save_plot(fig, 'scatterplot_engine_vs_price.png')

# 7. Scatterplot Seats vs Price
fig, ax = plt.subplots()
sns.scatterplot(x='Seats', y='Car Prices (USD)', data=df, ax=ax)
ax.set_title('Scatterplot: Seats vs Car Price')
save_plot(fig, 'scatterplot_seats_vs_price.png')

# 8. Scatterplot Transmission vs Price
fig, ax = plt.subplots()
sns.scatterplot(x='Transmission', y='Car Prices (USD)', data=df, ax=ax)
ax.set_title('Scatterplot: Transmission vs Car Price')
save_plot(fig, 'scatterplot_transmission_vs_price.png')

# 9. Countplot of Fuel Types
fig, ax = plt.subplots()
sns.countplot(x='Fuel Type', data=df, ax=ax)
ax.set_title('Count of Cars by Fuel Type')
save_plot(fig, 'countplot_fuel_type.png')

# 10. Pie Chart of Car Brand Region
fig, ax = plt.subplots()
df['Car Brand Region'].value_counts().plot.pie(autopct='%1.1f%%', ax=ax)
ax.set_ylabel('')
ax.set_title('Car Brand Region Distribution')
save_plot(fig, 'pie_brand_region.png')

# 11. Pairplot of Selected Features
pairplot_fig = sns.pairplot(df[['Car Prices (USD)', 'Distance driven (in miles)', 'Engine (cc)', 'Seats']])
pairplot_fig.fig.suptitle('Pairplot of Key Features', y=1.02)
pairplot_fig.savefig('plots/pairplot_features.png')
plt.close()

# 12. Violinplot Fuel Type vs Price
fig, ax = plt.subplots()
sns.violinplot(x='Fuel Type', y='Car Prices (USD)', data=df, ax=ax)
ax.set_title('Car Prices by Fuel Type')
save_plot(fig, 'violinplot_fuel_vs_price.png')

# 13. Correlation Heatmap
fig, ax = plt.subplots(figsize=(10,8))
corr_matrix = df.select_dtypes(include=['int64', 'float64']).corr()
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', ax=ax)
ax.set_title('Correlation Matrix')
save_plot(fig, 'correlation_matrix.png')

# Normalize features and labels
features = ['Distance driven (in miles)', 'Fuel Type', 'Transmission', 'Ownership',
            'Manufacture', 'Engine (cc)', 'Seats', 'Car Brand Region']

X_raw = df[features].values
X_mean = X_raw.mean(axis=0)
X_std = X_raw.std(axis=0)
X = (X_raw - X_mean) / X_std

y = df['Car Prices (USD)'].values.reshape(-1, 1)
y_mean = y.mean()
y_std = y.std()
y_norm = (y - y_mean) / y_std

# Train/test split
np.random.seed(42)
indices = np.random.permutation(X.shape[0])
split_idx = int(0.8 * X.shape[0])
train_idx, test_idx = indices[:split_idx], indices[split_idx:]
X_train, X_test = X[train_idx], X[test_idx]
y_train, y_test = y[train_idx], y[test_idx]
y_train_norm, y_test_norm = y_norm[train_idx], y_norm[test_idx]

# Define neural network building blocks
def sigmoid(x):
    x = np.clip(x, -500, 500)
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

def initialize_parameters(input_size, hidden_size, output_size):
    np.random.seed(42)
    W1 = np.random.randn(input_size, hidden_size) * 0.01
    W2 = np.random.randn(hidden_size + 1, output_size) * 0.01
    return W1, W2

def forward(X, W1, W2):
    X_bias = np.hstack((np.ones((X.shape[0], 1)), X))
    z1 = np.dot(X_bias, W1)
    a1 = sigmoid(z1)
    a1_bias = np.hstack((np.ones((a1.shape[0], 1)), a1))
    z2 = np.dot(a1_bias, W2)
    a2 = z2  # Linear output
    return z1, a1_bias, z2, a2

def mse(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

def rmse(y_true, y_pred):
    return np.sqrt(mse(y_true, y_pred))

# Train function for batch and stochastic gradient descent
def train(X, y, hidden_size=16, epochs=100, learning_rate=0.001, mode='batch'):
    input_size = X.shape[1] + 1
    output_size = 1
    W1, W2 = initialize_parameters(input_size, hidden_size, output_size)
    losses = []

    for epoch in range(epochs):
        if mode == 'batch':
            _, a1, _, a2 = forward(X, W1, W2)
            error_output = a2 - y
            error_hidden = np.dot(error_output, W2[1:].T) * sigmoid_derivative(a1[:, 1:])
            dW2 = np.dot(a1.T, error_output) / X.shape[0]
            dW1 = np.dot(np.hstack((np.ones((X.shape[0], 1)), X)).T, error_hidden) / X.shape[0]
            W2 -= learning_rate * dW2
            W1 -= learning_rate * dW1
            losses.append(rmse(y, a2))

        elif mode == 'stochastic':
            for i in range(X.shape[0]):
                xi = X[i:i+1]
                yi = y[i:i+1]
                _, a1, _, a2 = forward(xi, W1, W2)
                error_output = a2 - yi
                error_hidden = np.dot(error_output, W2[1:].T) * sigmoid_derivative(a1[:, 1:])
                dW2 = np.dot(a1.T, error_output)
                dW1 = np.dot(np.hstack((np.ones((xi.shape[0], 1)), xi)).T, error_hidden)
                W2 -= learning_rate * dW2
                W1 -= learning_rate * dW1
            _, _, _, a2_epoch = forward(X, W1, W2)
            losses.append(rmse(y, a2_epoch))

    return W1, W2, losses

# Predict function for new examples
def predict(X_new, W1, W2, X_mean, X_std, y_mean, y_std):
    if X_new.ndim == 1:
        X_new = X_new.reshape(1, -1)
    X_new_norm = (X_new - X_mean) / X_std
    _, _, _, y_pred_norm = forward(X_new_norm, W1, W2)
    return (y_pred_norm * y_std) + y_mean

# Save trained model parameters
def save_model_parameters(filename, W1, W2, learning_rate, epochs, final_rmse):
    with open(filename, 'w') as f:
        f.write("Feedforward Neural Network - Car Price Prediction\n")
        f.write("="*50 + "\n")
        f.write(f"Learning Rate: {learning_rate}\n")
        f.write(f"Number of Epochs: {epochs}\n")
        f.write(f"Final RMSE: {final_rmse:.6f}\n")
        f.write("="*50 + "\n\n")

        f.write("[Network Structure]\n")
        f.write(f"Input Layer Size: {W1.shape[0]}\n")
        f.write(f"Hidden Layer Size: {W1.shape[1]}\n")
        f.write(f"Output Layer Size: {W2.shape[1]}\n\n")

        f.write("[Weights: Input → Hidden Layer]\n")
        np.savetxt(f, W1, fmt="%.6f")

        f.write("\n[Weights: Hidden → Output Layer]\n")
        np.savetxt(f, W2, fmt="%.6f")

# Training Section
# Batch Gradient Descent Training
W1_batch, W2_batch, losses_batch = train(X_train, y_train_norm, mode='batch')

# Stochastic Gradient Descent Training
W1_stochastic, W2_stochastic, losses_stochastic = train(X_train, y_train_norm, mode='stochastic')

# Save Models
save_model_parameters('NNCarPriceParameters_Batch.txt', W1_batch, W2_batch, 0.001, 100, losses_batch[-1])
save_model_parameters('NNCarPriceParameters_Stochastic.txt', W1_stochastic, W2_stochastic, 0.001, 100, losses_stochastic[-1])

# Prediction Example
prediction = predict(X_test[0], W1_batch, W2_batch, X_mean, X_std, y_mean, y_std)
print(f"Predicted Car Price (USD): {prediction[0][0]:.2f}")

# Save RMSE curve separately
fig, ax = plt.subplots(figsize=(12,6))
ax.plot(losses_batch, label='Batch Gradient Descent')
ax.plot(losses_stochastic, label='Stochastic Gradient Descent')
ax.set_title('Training RMSE over Epochs')
ax.set_xlabel('Epoch')
ax.set_ylabel('RMSE')
ax.legend()
ax.grid(True)
save_plot(fig, 'training_rmse_curve.png')